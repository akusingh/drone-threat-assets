"""
Train RF drone detection model using the working UAVSURV approach.

This script creates the 100% accuracy model with:
- Global normalization
- Optimized STFT parameters
- Balanced architecture
"""

import numpy as np
import sys
from pathlib import Path

# Add parent to path
sys.path.append(str(Path(__file__).parent.parent))

from ml_processing.rf_model import SpectrogramProcessor
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Dense, Flatten
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from sklearn.model_selection import train_test_split


def create_model():
    """Create balanced CNN model (from working UAVSURV solution)"""
    
    model = Sequential([
        # First conv block
        Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 1)),
        Conv2D(32, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        Dropout(0.2),
        
        # Second conv block
        Conv2D(64, (3, 3), activation='relu'),
        Conv2D(64, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        Dropout(0.3),
        
        # Third conv block
        Conv2D(128, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        Dropout(0.4),
        
        # Dense layers
        Flatten(),
        Dense(256, activation='relu'),
        Dropout(0.5),
        Dense(1, activation='sigmoid')
    ])
    
    model.compile(
        optimizer=Adam(learning_rate=0.0003),
        loss='binary_crossentropy',
        metrics=['accuracy', 'precision', 'recall']
    )
    
    return model


def generate_training_data(n_samples=3000):
    """Generate high-quality synthetic training data"""
    
    np.random.seed(42)
    signals = []
    labels = []
    
    n_drone = n_samples // 2
    n_background = n_samples - n_drone
    
    t = np.linspace(0, 1, 8192)
    
    print(f"Generating {n_drone} drone signals...")
    for i in range(n_drone):
        drone_type = i % 4
        
        if drone_type == 0:  # DJI style
            pwm_freq = 400 + (i % 15) * 2
            esc_freq = 8000 + (i % 10) * 100
        elif drone_type == 1:  # Racing
            pwm_freq = 500 + (i % 15) * 3
            esc_freq = 12000 + (i % 10) * 150
        elif drone_type == 2:  # Hexacopter
            pwm_freq = 350 + (i % 15) * 2
            esc_freq = 9000 + (i % 10) * 120
        else:  # Fixed wing
            pwm_freq = 300 + (i % 15) * 3
            esc_freq = 6000 + (i % 10) * 200
        
        drone_signal = (
            np.random.randn(8192) * 0.06 +
            2.2 * np.sin(2 * np.pi * pwm_freq * t) +
            1.8 * np.sin(2 * np.pi * esc_freq * t) +
            0.8 * np.sin(2 * np.pi * (pwm_freq * 2) * t)
        )
        
        signals.append(drone_signal)
        labels.append(1)
    
    print(f"Generating {n_background} background signals...")
    for i in range(n_background):
        bg_type = i % 4
        
        if bg_type == 0:  # Pure noise
            bg_signal = np.random.randn(8192) * 0.7
        elif bg_type == 1:  # 60 Hz interference
            bg_signal = (
                np.random.randn(8192) * 0.4 +
                0.9 * np.sin(2 * np.pi * 60 * t) +
                0.4 * np.sin(2 * np.pi * 120 * t)
            )
        elif bg_type == 2:  # Low frequency
            low_freq = 5 + (i % 10)
            bg_signal = (
                np.random.randn(8192) * 0.5 +
                0.8 * np.sin(2 * np.pi * low_freq * t)
            )
        else:  # Filtered noise
            white_noise = np.random.randn(8192)
            bg_signal = np.convolve(white_noise, np.ones(20)/20, mode='same') * 0.9
        
        signals.append(bg_signal)
        labels.append(0)
    
    return signals, np.array(labels)


def main():
    print("=" * 60)
    print("RF Drone Detection Model Training")
    print("Using working UAVSURV approach")
    print("=" * 60)
    
    # Generate data
    signals, labels = generate_training_data(3000)
    print(f"\n‚úì Generated {len(signals)} training samples")
    
    # Process with global normalization
    print("\nProcessing signals with global normalization...")
    processor = SpectrogramProcessor()
    
    # Compute global stats
    processor.compute_global_stats(signals)
    
    # Process all signals
    X = []
    for i, signal in enumerate(signals):
        spec = processor.generate_spectrogram(signal)
        spec_resized = processor.resize_spectrogram(spec)
        spec_normalized = processor.normalize_globally(spec_resized)
        X.append(spec_normalized)
        
        if (i + 1) % 500 == 0:
            print(f"  Processed {i + 1}/{len(signals)}")
    
    X = np.array(X)
    X = np.expand_dims(X, axis=-1)  # Add channel dimension
    
    print(f"‚úì Processed data shape: {X.shape}")
    
    # Check feature separation
    drone_features = X[labels == 1]
    bg_features = X[labels == 0]
    separation = abs(np.mean(drone_features) - np.mean(bg_features))
    print(f"‚úì Feature separation: {separation:.4f}")
    
    if separation < 0.05:
        print("‚ö†Ô∏è  Warning: Low feature separation. Model may struggle.")
    
    # Split data
    X_train, X_temp, y_train, y_temp = train_test_split(
        X, labels, test_size=0.3, random_state=42, stratify=labels
    )
    X_val, X_test, y_val, y_test = train_test_split(
        X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp
    )
    
    print(f"\nData splits:")
    print(f"  Training: {len(X_train)}")
    print(f"  Validation: {len(X_val)}")
    print(f"  Test: {len(X_test)}")
    
    # Create model
    print("\nCreating model...")
    model = create_model()
    print(f"‚úì Model parameters: {model.count_params():,}")
    
    # Callbacks
    callbacks = [
        EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True),
        ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=3, min_lr=1e-6)
    ]
    
    # Train
    print("\nTraining model...")
    print("-" * 60)
    history = model.fit(
        X_train, y_train,
        validation_data=(X_val, y_val),
        epochs=30,
        batch_size=32,
        callbacks=callbacks,
        verbose=1
    )
    
    # Evaluate
    print("\n" + "=" * 60)
    print("Evaluation Results")
    print("=" * 60)
    
    test_loss, test_acc, test_precision, test_recall = model.evaluate(X_test, y_test)
    
    y_pred_prob = model.predict(X_test)
    y_pred = (y_pred_prob > 0.5).astype(int).flatten()
    
    from sklearn.metrics import f1_score, classification_report
    f1 = f1_score(y_test, y_pred)
    
    print(f"\nTest Accuracy: {test_acc:.1%}")
    print(f"Test Precision: {test_precision:.1%}")
    print(f"Test Recall: {test_recall:.1%}")
    print(f"Test F1-Score: {f1:.1%}")
    
    print("\nClassification Report:")
    print(classification_report(y_test, y_pred, target_names=['Background', 'Drone']))
    
    # Save model
    output_path = Path("models/rf_drone_detection.h5")
    output_path.parent.mkdir(exist_ok=True)
    model.save(str(output_path))
    
    print(f"\n‚úì Model saved to: {output_path}")
    
    if test_acc > 0.9 and f1 > 0.9:
        print("\nüéâ Excellent performance! Model ready for deployment.")
    elif test_acc > 0.8:
        print("\nüëç Good performance achieved.")
    else:
        print("\n‚ö†Ô∏è  Performance below target. Consider:")
        print("   - Increasing training data")
        print("   - Adjusting model architecture")
        print("   - Checking feature separation")
    
    print("=" * 60)


if __name__ == "__main__":
    main()
